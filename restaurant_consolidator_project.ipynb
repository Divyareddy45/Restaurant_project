{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9685c4",
   "metadata": {},
   "source": [
    "# Restaurant Consolidator — B2C Portal Revamp (Intelligent Automation)\n",
    "**Notebook created:** 2025-11-05 17:42:32\n",
    " \n",
    "**Goal:** Provide a complete end-to-end exploratory data analysis, cleaning, and feature inspection workflow to identify *star restaurants* and generate recommendations. This notebook is produced as a deliverable for the uploaded dataset (zip file) and includes code, explanations, and visualizations. Use this notebook as the base for modeling or Tableau dashboard creation.\n",
    "\n",
    "**Files expected (from provided zip):**\n",
    "- `data` — main dataset with 19 attributes\n",
    "- `Country-Code` — country code mapping (2 attributes)\n",
    "\n",
    "The notebook performs:\n",
    "1. Importing, understanding and inspecting data (structure, missing values, duplicates)\n",
    "2. Cleaning (duplicate removal, basic imputations)\n",
    "3. EDA: geography, franchising, table booking, delivery, votes\n",
    "4. EDA: cuisines, cost distribution, ratings, factors affecting ratings\n",
    "5. Visualizations (matplotlib) and suggestions for Tableau dashboarding\n",
    "6. Next steps: recommend metrics and simple recipe for building a recommendation engine\n",
    "\n",
    "**How to run:** Execute all cells in order. The notebook attempts to locate the zip file at `/mnt/data/1683266696_dataset (2).zip` — change the path if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unzip the provided dataset and list files\n",
    "import zipfile, os, sys, pathlib\n",
    "zip_path = r\"/mnt/data/1683266696_dataset (2).zip\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Zip file not found at:\", zip_path)\n",
    "    print(\"Please upload the dataset zip to /mnt/data or update the path.\")\n",
    "else:\n",
    "    extract_to = \"/mnt/data/restaurant_dataset_extracted\"\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_to)\n",
    "    print(\"Extracted to:\", extract_to)\n",
    "    for root, dirs, files in os.walk(extract_to):\n",
    "        for f in files:\n",
    "            print(os.path.join(root,f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports and display settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "import os, textwrap\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.width', 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b781369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attempt to locate main data files inside extracted folder\n",
    "base = \"/mnt/data/restaurant_dataset_extracted\"\n",
    "candidates = []\n",
    "for root, dirs, files in os.walk(base):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(('.csv', '.txt', '.xls', '.xlsx')):\n",
    "            candidates.append(os.path.join(root,f))\n",
    "candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Heuristic loader: choose likely files by name\n",
    "candidates = _  # from previous cell's output\n",
    "data_path = None\n",
    "country_code_path = None\n",
    "\n",
    "for p in candidates:\n",
    "    name = os.path.basename(p).lower()\n",
    "    if 'country' in name or 'country-code' in name or 'country code' in name:\n",
    "        country_code_path = p\n",
    "    if 'data' == os.path.splitext(name)[0] or 'data.csv' in name or 'zomato' in name or 'restaurant' in name:\n",
    "        data_path = p\n",
    "\n",
    "# fallback: if only two CSVs present, assign them\n",
    "if not data_path and len(candidates)>=1:\n",
    "    data_path = candidates[0]\n",
    "if not country_code_path and len(candidates)>=2:\n",
    "    country_code_path = candidates[1]\n",
    "\n",
    "print(\"Data file:\", data_path)\n",
    "print(\"Country code file:\", country_code_path)\n",
    "\n",
    "# Load files if found\n",
    "data = pd.read_csv(data_path, encoding='latin1') if data_path else None\n",
    "country_code = pd.read_csv(country_code_path, encoding='latin1') if country_code_path else None\n",
    "\n",
    "print(\"Data shape:\", None if data is None else data.shape)\n",
    "print(\"Country code shape:\", None if country_code is None else country_code.shape)\n",
    "\n",
    "# show top rows\n",
    "display(data.head())\n",
    "display(country_code.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e53839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Preliminary data inspection\n",
    "def inspect_df(df, name=\"data\"):\n",
    "    display(Markdown(f\"### Inspecting `{name}`\"))\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"\\nColumn dtypes:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nMissing values (per column):\")\n",
    "    print(df.isnull().sum().sort_values(ascending=False).head(20))\n",
    "    print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "    print(\"\\nSample rows:\")\n",
    "    display(df.sample(5, random_state=42))\n",
    "\n",
    "inspect_df(data, \"data\")\n",
    "inspect_df(country_code, \"country_code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Identify duplicates and remove them (from `data`)\n",
    "initial_shape = data.shape\n",
    "dupe_count = data.duplicated().sum()\n",
    "print(\"Initial shape:\", initial_shape)\n",
    "print(\"Duplicate rows found:\", dupe_count)\n",
    "\n",
    "# Inspect duplicates (example)\n",
    "if dupe_count>0:\n",
    "    display(data[data.duplicated(keep=False)].head(10))\n",
    "\n",
    "# Drop exact duplicate rows\n",
    "data_clean = data.drop_duplicates().copy()\n",
    "print(\"Shape after removing exact duplicates:\", data_clean.shape)\n",
    "\n",
    "# If there are duplicates based on subset keys (like Restaurant ID, Name + Address), attempt to drop\n",
    "# Heuristic: common keys 'Restaurant ID', 'Restaurant_ID', 'Restaurant ID', 'url' might exist\n",
    "possible_id_cols = [c for c in data_clean.columns if any(x in c.lower() for x in ['id','restaurant id','res_id','res id','name'])]\n",
    "possible_id_cols[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd025e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Geographical distribution: cities with max and min restaurants\n",
    "# We'll attempt to find likely city and country columns\n",
    "cols = [c.lower() for c in data_clean.columns]\n",
    "city_col = None\n",
    "country_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'city' in c.lower():\n",
    "        city_col = c\n",
    "    if 'country' in c.lower():\n",
    "        country_col = c\n",
    "\n",
    "print(\"Detected city column:\", city_col)\n",
    "print(\"Detected country column:\", country_col)\n",
    "\n",
    "if city_col:\n",
    "    city_counts = data_clean[city_col].value_counts(dropna=False)\n",
    "    display(city_counts.head(10))\n",
    "    max_city = city_counts.idxmax()\n",
    "    min_city = city_counts[city_counts>0].idxmin()\n",
    "    print(f\"City with maximum restaurants: {max_city} ({city_counts.max()})\")\n",
    "    print(f\"City with minimum restaurants (non-zero): {min_city} ({city_counts[city_counts>0].min()})\")\n",
    "\n",
    "# 4. Franchise with most national presence\n",
    "# Find a column likely to indicate 'is franchise' or 'has franchise' or 'chain'\n",
    "chain_col = None\n",
    "for c in data_clean.columns:\n",
    "    if any(k in c.lower() for k in ['chain','franchise','establishment','brand']):\n",
    "        chain_col = c\n",
    "        break\n",
    "print(\"Detected chain/franchise-like column:\", chain_col)\n",
    "\n",
    "# If dataset has 'Restaurant Name' we can count occurrences\n",
    "name_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'name' in c.lower():\n",
    "        name_col = c\n",
    "        break\n",
    "\n",
    "if name_col and city_col:\n",
    "    franchise_counts = data_clean.groupby(name_col)[city_col].nunique().sort_values(ascending=False)\n",
    "    display(franchise_counts.head(10))\n",
    "    print(\"Franchise with most national presence (based on unique cities):\")\n",
    "    display(franchise_counts.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Table booking ratio\n",
    "tb_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'table' in c.lower() and 'book' in c.lower():\n",
    "        tb_col = c\n",
    "        break\n",
    "print(\"Detected table booking column:\", tb_col)\n",
    "\n",
    "if tb_col:\n",
    "    tb_counts = data_clean[tb_col].value_counts(dropna=False)\n",
    "    display(tb_counts)\n",
    "    tb_yes = tb_counts.get('Yes', tb_counts.get('yes', tb_counts.get(1,0)))\n",
    "    tb_no = tb_counts.get('No', tb_counts.get('no', tb_counts.get(0,0)))\n",
    "    total = tb_counts.sum()\n",
    "    print(f\"Table booking ratio: Yes {tb_yes}/{total} = {tb_yes/total:.2%}, No {tb_no}/{total} = {tb_no/total:.2%}\")\n",
    "\n",
    "# 6. Percentage of restaurants providing online delivery\n",
    "od_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'online' in c.lower() and 'delivery' in c.lower() or c.lower()=='online_delivery' or 'deliv' in c.lower() and 'online' in c.lower():\n",
    "        od_col = c\n",
    "        break\n",
    "# fallback search for 'delivery' column\n",
    "if not od_col:\n",
    "    for c in data_clean.columns:\n",
    "        if 'delivery' in c.lower():\n",
    "            od_col = c\n",
    "            break\n",
    "\n",
    "print(\"Detected delivery column:\", od_col)\n",
    "if od_col:\n",
    "    od_counts = data_clean[od_col].value_counts(dropna=False)\n",
    "    display(od_counts.head(10))\n",
    "    # Try parse yes/no or 1/0\n",
    "    online_yes = od_counts.get('Yes', od_counts.get('yes', od_counts.get(1,0)))\n",
    "    total = od_counts.sum()\n",
    "    print(f\"Online delivery percentage: {online_yes}/{total} = {online_yes/total:.2%}\")\n",
    "\n",
    "# 7. Difference in number of votes for restaurants that deliver vs those that do not deliver\n",
    "votes_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'vote' in c.lower() or 'votes' in c.lower() or 'votes_count' in c.lower():\n",
    "        votes_col = c\n",
    "        break\n",
    "print(\"Detected votes column:\", votes_col)\n",
    "if votes_col and od_col:\n",
    "    # convert votes to numeric if needed\n",
    "    data_clean['__votes_num__'] = pd.to_numeric(data_clean[votes_col], errors='coerce')\n",
    "    grp = data_clean.groupby(data_clean[od_col].astype(str))['__votes_num__'].agg(['count','mean','sum','median']).sort_values('mean', ascending=False)\n",
    "    display(grp)\n",
    "    # difference in total votes between deliverers and non-deliverers (if values present)\n",
    "    vals = grp['sum']\n",
    "    if len(vals)>=2:\n",
    "        print(\"Difference in total votes between top two delivery groups:\", vals.iloc[0] - vals.iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ffb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Top 10 cuisines across cities (or overall)\n",
    "# Find cuisine column\n",
    "cuisine_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'cuisine' in c.lower() or 'cuisines' in c.lower():\n",
    "        cuisine_col = c\n",
    "        break\n",
    "print(\"Detected cuisine column:\", cuisine_col)\n",
    "\n",
    "if cuisine_col:\n",
    "    # cuisines might be pipe/comma separated\n",
    "    s = data_clean[cuisine_col].dropna().astype(str)\n",
    "    # split by common separators\n",
    "    import re\n",
    "    split_cuisines = s.str.split(r',|\\||;')\n",
    "    exploded = split_cuisines.explode().str.strip().str.title()\n",
    "    top10 = exploded.value_counts().head(20)\n",
    "    display(top10.head(10))\n",
    "\n",
    "    # Max and min number of cuisines a restaurant serves\n",
    "    cuisine_counts = split_cuisines.apply(lambda x: len([i for i in x if str(i).strip()!='']) if isinstance(x,list) else 0)\n",
    "    print(\"Max cuisines per restaurant:\", cuisine_counts.max())\n",
    "    print(\"Min cuisines per restaurant:\", cuisine_counts.min())\n",
    "\n",
    "    # Most served cuisine for each city\n",
    "    if city_col:\n",
    "        def most_common_in_city(df, city):\n",
    "            csplit = df[df[city_col]==city][cuisine_col].dropna().astype(str).str.split(r',|\\||;').explode().str.strip().str.title()\n",
    "            if len(csplit):\n",
    "                return csplit.value_counts().idxmax()\n",
    "            return None\n",
    "        top_cuisine_by_city = {city: most_common_in_city(data_clean, city) for city in data_clean[city_col].dropna().unique()}\n",
    "        # display for top 10 cities\n",
    "        list(top_cuisine_by_city.items())[:10]\n",
    "\n",
    "# 3. Cost distribution across restaurants\n",
    "cost_col = None\n",
    "for c in data_clean.columns:\n",
    "    if 'cost' in c.lower() or 'price' in c.lower():\n",
    "        cost_col = c\n",
    "        break\n",
    "print(\"Detected cost column:\", cost_col)\n",
    "if cost_col:\n",
    "    # Try to coerce to numeric (remove non-digits)\n",
    "    data_clean['__cost_num__'] = pd.to_numeric(data_clean[cost_col].astype(str).str.replace(r'[^0-9\\.]','', regex=True), errors='coerce')\n",
    "    display(data_clean['__cost_num__'].describe())\n",
    "    # histogram\n",
    "    plt.figure(figsize=(8,4))\n",
    "    data_clean['__cost_num__'].dropna().hist(bins=30)\n",
    "    plt.title(\"Cost distribution (numeric)\")\n",
    "    plt.xlabel(\"Cost for two (approx)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# 4. Ratings distribution among various factors\n",
    "# Find rating columns (may include 'Aggregate rating' and 'Rating text' etc.)\n",
    "rating_cols = [c for c in data_clean.columns if 'rating' in c.lower() or 'rate' in c.lower()]\n",
    "print(\"Detected rating-like columns:\", rating_cols)\n",
    "for rc in rating_cols:\n",
    "    try:\n",
    "        vals = pd.to_numeric(data_clean[rc], errors='coerce')\n",
    "        print(f\"\\nStats for {rc}:\")\n",
    "        display(vals.describe())\n",
    "        plt.figure(figsize=(6,3))\n",
    "        vals.dropna().hist(bins=20)\n",
    "        plt.title(f\"Distribution of {rc}\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Could not plot\", rc, e)\n",
    "\n",
    "# 5. Factors that may affect ratings: quick correlation and group comparisons\n",
    "# Prepare a working DF with numeric candidates\n",
    "work = data_clean.copy()\n",
    "num_cols = []\n",
    "for c in work.columns:\n",
    "    if work[c].dtype in [np.float64, np.int64] or c in ['__votes_num__','__cost_num__']:\n",
    "        num_cols.append(c)\n",
    "# Ensure rating column present for correlation (choose first numeric rating-like column)\n",
    "rating_numeric = None\n",
    "for rc in rating_cols:\n",
    "    tmp = pd.to_numeric(work[rc], errors='coerce')\n",
    "    if tmp.notnull().sum()>0:\n",
    "        work['__rating__'] = tmp\n",
    "        rating_numeric = '__rating__'\n",
    "        break\n",
    "\n",
    "print(\"Numeric columns considered:\", num_cols)\n",
    "print(\"Chosen numeric rating column:\", rating_numeric)\n",
    "\n",
    "if rating_numeric:\n",
    "    corr = work[[c for c in num_cols if c in work.columns] + [rating_numeric]].corr()[rating_numeric].sort_values(ascending=False)\n",
    "    display(corr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.barh(corr.index, corr.values)\n",
    "    plt.title(\"Correlation with rating (numeric features)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6-7. Tableau guidance\n",
    "display(Markdown(\"## Tableau Dashboarding Guidance\"))\n",
    "display(Markdown(textwrap.dedent(\\\"\\\"\\\"\n",
    "Suggested dashboards and worksheets to create in Tableau (data fields referenced are approximate — adjust to your actual column names):\n",
    "\n",
    "1. **Overview / Map**: Plot restaurants on a map (use city or lat/lon if available). Size by number of votes, color by average rating. Filters: country, city, cuisine, cost for two, delivery/table booking flags.\n",
    "2. **Top Restaurants / 'Star' Detection**: Create a composite 'star score' that combines normalized rating, votes, delivery availability, and (optionally) number of cuisines or cost bracket. Show top N restaurants with bar chart and table.\n",
    "3. **Franchise Reach**: Horizontal bar showing number of unique cities per brand (restaurant name) to find franchises with widest presence.\n",
    "4. **Cuisines Analysis**: Treemap or bar chart of top cuisines overall and by city. Enable filter to select city and see top cuisines there.\n",
    "5. **Delivery vs Ratings**: Boxplot or violin plot comparing ratings for restaurants that deliver vs those who don't. Add filters for cuisine or cost brackets.\n",
    "6. **Operational KPIs**: Percentage of restaurants providing online delivery, table booking ratio, average votes per restaurant, etc. Visualize as KPI tiles or donut charts.\n",
    "\n",
    "**Calculated fields to create in Tableau** (examples):\n",
    "- `Normalized Rating` = (`Rating` - WINDOW_MIN(Rating))/(WINDOW_MAX(Rating)-WINDOW_MIN(Rating))\n",
    "- `Star Score` = 0.6 * `Normalized Rating` + 0.2 * LOG(`Votes`+1) + 0.1 * `Has Online Delivery` + 0.1 * `Has Table Booking`\n",
    "\n",
    "\\\"\\\"\\\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9979d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recommendation Engine — Simple recipe (no modeling code here, just guidance)\n",
    "display(Markdown(\"## Recommendation Engine — Suggested approach\"))\n",
    "\n",
    "display(Markdown(textwrap.dedent(\\\"\\\"\\\"\n",
    "1. **Feature engineering**:\n",
    "   - Numeric features: normalized rating, log(votes+1), cost bracket, number of cuisines.\n",
    "   - Binary flags: provides_delivery, provides_table_booking, is_franchise, has_online_order.\n",
    "   - Categorical: city, cuisines (one-hot or embedding), restaurant type.\n",
    "\n",
    "2. **User-item signals** (if available): past orders, clicks, favorites. If not available, create implicit signals using popularity (votes, visits) and recency.\n",
    "\n",
    "3. **Model options**:\n",
    "   - Content-based: compute similarity between restaurants using cuisine vectors + numeric features (cosine similarity). Recommend nearest neighbors.\n",
    "   - Collaborative / Hybrid: if user interaction data exists, use matrix factorization or LightFM / implicit libraries to combine content and collaborative signals.\n",
    "   - Ranking: train a learning-to-rank model using features above to rank candidate restaurants for a user/city.\n",
    "\n",
    "4. **Evaluation metrics**: Precision@K, Recall@K, NDCG, and offline A/B testing for live results.\n",
    "\n",
    "5. **Deployment**: Precompute embeddings and nearest neighbors (using Annoy, Faiss) for fast online recommendations.\n",
    "\\\"\\\"\\\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6792e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (This cell is informative — the notebook file has already been written by the creator script. \n",
    "# If you re-run or modify the notebook, save using the Jupyter UI or this command:)\n",
    "# nbformat.write(nb, \"restaurant_consolidator_project.ipynb\")\n",
    "print(\"Notebook ready. Use 'File -> Download' in the Jupyter UI to get the .ipynb, or use the provided download link.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
